= Mongolastic
:version: v1.3.8

image:https://travis-ci.org/ozlerhakan/mongolastic.svg?branch=master["Build Status", link="https://travis-ci.org/ozlerhakan/mongolastic"] image:https://img.shields.io/badge/license-MIT-blue.svg[] image:https://img.shields.io/badge/mongo.java.driver-3.2.2-brightgreen.svg[] image:https://img.shields.io/badge/elastic.java.driver-2.3.3-brightgreen.svg[]

What data you have in your MongoDB can also be included into your ElasticSearch and vice versa using this tool. You can perform the aforementioned facilities by providing a file having a yaml characteristic.

== How it works

First, download the latest https://github.com/ozlerhakan/mongolastic/releases/download/{version}/mongolastic.jar[mongolastic.jar] file.

Second, give a yaml file which must contain the following structure:

[source,yaml]
----
misc:
    dindex:
        name: <string>      <1>
        as: <string>        <2>
    ctype:
        name: <string>      <3>
        as: <string>        <4>
    direction: (em | me)    <5>
    batch: <number>         <6>
    dropDataset: <bool>     <7>
mongo:
    host: <ip-address>      <8>
    port: <number>          <9>
    query: "mongo-query"    <10>
    auth:                   <11>
        user: <string>
        pwd: "password"
        source: <db-name>
        mechanism: ( plain | scram-sha-1 | x509 | gssapi | cr )
elastic:
    host: <ip-address>     <12>
    port: <number>         <13>
    dateFormat: "<format>" <14>
    longToString: <bool>   <15>
    auth:                   <16>
        user: <string>
        pwd: "password"
----
<1>  the _database/index name_ to connect to.
<2>  another _database/index name_ in which documents will be located in the target service (*Optional*)
<3>  the _collection/type name_ to export.
<4>  another _collection/type name_ in which indexed/collected documents will reside in the target service (*Optional*)
<5>  direction of the data transfer. the default direction is me (that is, mongo to elasticsearch). You can skip this option if your data move from mongo to es.
<6>  Override the default batch size which is normally 200. (*Optional*)
<7>  configures whether or not the target table should be dropped prior to loading data. Default value is true (*Optional*)
<8>  the name of the host machine where the `mongod` is running.
<9>  the port where the `mongod` instance is listening.
<10>  data will be transferred based on a json mongodb query (*Optional*)
<11> as of v1.3.5, you can access an auth mongodb by giving auth configuration. (*Optional*)
<12> the name of the host machine where the `elastic node` is running.
<13> the *transport* port where the transport module will communicate with the running elastic node. E.g. *9300* for node-to-node communication.
<14> a custom formatter for Date fields rather than the default DateCodec (*Optional*)
<15> serialize long value as a string for backwards compatibility with other tools (*Optional*)
<16> as of v1.3.9, you can access an auth elastic search by giving auth configuration. (*Optional*)

Here is an example of a configuration file:

[source,yaml]
----
misc:
    dindex:
        name: twitter
        as: kodcu
    ctype:
        name: tweets
        as: posts
mongo:
    host: localhost
    port: 27017
    query: "{ 'user.name' : 'kodcu.com'}"
elastic:
    host: localhost
    port: 9300
----
the config says that the transfer direction is from mongodb to elasticsearch, mongolastic first looks at the _tweets_ collection, where the _user name_ is _kodcu.com_, of the _twitter_ database located on a mongod server running on default host interface and port number. If It finds the corresponding data, It will start copying those into an elasticsearch environment running on default host and transport number. After all, you should see a type called _"posts"_ in an index called _"kodcu"_ in the current elastic node. Why the index and type are different is because "dindex.as" and "ctype.as" options were set, these indicates that your data being transferred exist in _posts_ type of the _kodcu_ index. Additionally, all the test cases can run on Docker using `docker-compose`.

After downloading the jar and providing a conf file, you can run the tool as below:

    $ java -jar mongolastic.jar -f config.file

NOTE: Every attempt of running the tool drops the mentioned db/index in the target environment unless the dropDataset parameter is configured otherwise.

== License

Mongolastic is released under http://showalicense.com/?hide_explanations=false&year=2015&fullname=Kodcu.com#license-mit[MIT].
